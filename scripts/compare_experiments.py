#!/usr/bin/env python3
"""
å¯¹æ¯” exp001 å’Œ exp002 çš„å®Œæ•´è¯„ä¼°ç»“æœ
ç”Ÿæˆè¯¦ç»†çš„æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š
"""

import json
from pathlib import Path
from typing import Dict, Any

def load_eval_results(exp_dir: Path) -> Dict[str, Any]:
    """åŠ è½½å®éªŒçš„è¯„ä¼°ç»“æœ"""
    results = {
        'test_g': {},
        'test_a': {},
        'test_b': {},
        'conflict': None
    }
    
    eval_dir = exp_dir / 'eval_checkpoints'
    if not eval_dir.exists():
        return results
    
    # Load Test-G results
    for f in eval_dir.glob('test_g_*.json'):
        data = json.load(open(f))
        adapter_type = data.get('adapter_type', f.stem.replace('test_g_', ''))
        results['test_g'][adapter_type] = {
            'accuracy': data.get('accuracy', 0),
            'correct': data.get('correct', 0),
            'total': data.get('total', 0)
        }
    
    # Load Test-A results
    for f in eval_dir.glob('test_a_*.json'):
        data = json.load(open(f))
        adapter_type = data.get('adapter_type', f.stem.replace('test_a_', ''))
        results['test_a'][adapter_type] = {
            'accuracy': data.get('accuracy', 0),
            'correct': data.get('correct', 0),
            'total': data.get('total', 0)
        }
    
    # Load Test-B results
    for f in eval_dir.glob('test_b_*.json'):
        data = json.load(open(f))
        adapter_type = data.get('adapter_type', f.stem.replace('test_b_', ''))
        results['test_b'][adapter_type] = {
            'accuracy': data.get('accuracy', 0),
            'correct': data.get('correct', 0),
            'total': data.get('total', 0)
        }
    
    # Load Conflict test results
    metrics_dir = exp_dir / 'metrics'
    conflict_file = metrics_dir / 'conflict_test_results.json'
    if conflict_file.exists():
        results['conflict'] = json.load(open(conflict_file))
    
    return results

def print_section_header(title: str):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print(f"\n{'='*80}")
    print(f"{title:^80}")
    print(f"{'='*80}")

def print_test_comparison(test_name: str, exp001_data: Dict, exp002_data: Dict):
    """æ‰“å°å•ä¸ªæµ‹è¯•é›†çš„å¯¹æ¯”"""
    print(f"\n{test_name}")
    print("-" * 80)
    
    # è·å–æ‰€æœ‰ adapter ç±»å‹
    all_adapters = sorted(set(list(exp001_data.keys()) + list(exp002_data.keys())))
    
    if not all_adapters:
        print("   No data available")
        return
    
    # è¡¨å¤´
    print(f"{'Adapter Type':<20} {'EXP001':>15} {'EXP002':>15} {'Î”':>10}")
    print("-" * 80)
    
    # é€è¡Œå¯¹æ¯”
    for adapter in all_adapters:
        exp001_acc = exp001_data.get(adapter, {}).get('accuracy', 0)
        exp002_acc = exp002_data.get(adapter, {}).get('accuracy', 0)
        delta = exp002_acc - exp001_acc if exp001_acc > 0 else 0
        
        exp001_str = f"{exp001_acc:.1%}" if exp001_acc > 0 else "N/A"
        exp002_str = f"{exp002_acc:.1%}" if exp002_acc > 0 else "N/A"
        delta_str = f"{delta:+.1%}" if delta != 0 else "-"
        
        print(f"{adapter:<20} {exp001_str:>15} {exp002_str:>15} {delta_str:>10}")

def calculate_privacy_gap(test_data: Dict, strict_key: str, service_key: str) -> float:
    """è®¡ç®—éšç§ä¿æŠ¤å·®è·"""
    if strict_key in test_data and service_key in test_data:
        return test_data[strict_key]['accuracy'] - test_data[service_key]['accuracy']
    return 0.0

def main():
    results_dir = Path('results')
    
    # åŠ è½½ä¸¤ä¸ªå®éªŒçš„ç»“æœ
    exp001_results = load_eval_results(results_dir / 'exp001_dual_adapter_fl')
    exp002_results = load_eval_results(results_dir / 'exp002_improved_dual_adapter')
    
    print_section_header("å®éªŒå¯¹æ¯”æŠ¥å‘Šï¼šEXP001 vs EXP002")
    
    # å®éªŒé…ç½®å¯¹æ¯”
    print("\nğŸ“‹ å®éªŒé…ç½®")
    print("-" * 80)
    print(f"{'Parameter':<30} {'EXP001':<25} {'EXP002':<25}")
    print("-" * 80)
    print(f"{'LoRA Rank (r)':<30} {'16':<25} {'32':<25}")
    print(f"{'LoRA Alpha':<30} {'32':<25} {'64':<25}")
    print(f"{'Epochs per Round':<30} {'2':<25} {'3':<25}")
    print(f"{'Federated Rounds':<30} {'5':<25} {'5':<25}")
    print(f"{'Batch Size':<30} {'4':<25} {'4':<25}")
    
    # Test-G: é€šç”¨æ³•å¾‹çŸ¥è¯†ä¿æŒ
    print_test_comparison(
        "ğŸ“š Test-G: Universal Law Knowledge Retention",
        exp001_results['test_g'],
        exp002_results['test_g']
    )
    
    # Test-A: ä¸¥ç®¡åŸå¸‚æ”¿ç­–è®°å¿†
    print_test_comparison(
        "ğŸ”’ Test-A: Strict City Policy Memory",
        exp001_results['test_a'],
        exp002_results['test_a']
    )
    
    # è®¡ç®— Test-A çš„éšç§ä¿æŠ¤å·®è·
    exp001_privacy_a = calculate_privacy_gap(exp001_results['test_a'], 'strict', 'service')
    exp002_privacy_a = calculate_privacy_gap(exp002_results['test_a'], 'strict', 'service')
    
    if exp001_privacy_a > 0 or exp002_privacy_a > 0:
        print(f"\n   Privacy Gap (Strict - Service):")
        print(f"   EXP001: {exp001_privacy_a:+.1%}  |  EXP002: {exp002_privacy_a:+.1%}")
    
    # Test-B: æœåŠ¡å‹åŸå¸‚æ”¿ç­–è®°å¿†
    print_test_comparison(
        "ğŸ¤ Test-B: Service City Policy Memory",
        exp001_results['test_b'],
        exp002_results['test_b']
    )
    
    # è®¡ç®— Test-B çš„éšç§ä¿æŠ¤å·®è·
    exp001_privacy_b = calculate_privacy_gap(exp001_results['test_b'], 'service', 'strict')
    exp002_privacy_b = calculate_privacy_gap(exp002_results['test_b'], 'service', 'strict')
    
    if exp001_privacy_b > 0 or exp002_privacy_b > 0:
        print(f"\n   Privacy Gap (Service - Strict):")
        print(f"   EXP001: {exp001_privacy_b:+.1%}  |  EXP002: {exp002_privacy_b:+.1%}")
    
    # Conflict Test å¯¹æ¯”
    print_section_header("âš”ï¸  Conflict Test: Jurisdiction-Specific Response")
    
    exp001_conflict = exp001_results['conflict']
    exp002_conflict = exp002_results['conflict']
    
    if exp001_conflict or exp002_conflict:
        print(f"\n{'Metric':<30} {'EXP001':>15} {'EXP002':>15} {'Î”':>10}")
        print("-" * 80)
        
        if exp001_conflict and exp002_conflict:
            exp001_pass = exp001_conflict.get('pass_rate', 0)
            exp002_pass = exp002_conflict.get('pass_rate', 0)
            delta_pass = exp002_pass - exp001_pass
            
            print(f"{'Pass Rate':<30} {exp001_pass:>14.1%} {exp002_pass:>14.1%} {delta_pass:>9.1%}")
            print(f"{'Passed Cases':<30} {exp001_conflict.get('passed', 0):>15} {exp002_conflict.get('passed', 0):>15}")
            print(f"{'Failed Cases':<30} {exp001_conflict.get('failed', 0):>15} {exp002_conflict.get('failed', 0):>15}")
            print(f"{'Total Cases':<30} {exp001_conflict.get('total_cases', 0):>15} {exp002_conflict.get('total_cases', 0):>15}")
        elif exp001_conflict:
            print(f"{'Pass Rate':<30} {exp001_conflict.get('pass_rate', 0):>14.1%} {'Pending':>15}")
        elif exp002_conflict:
            print(f"{'Pass Rate':<30} {'Pending':>15} {exp002_conflict.get('pass_rate', 0):>14.1%}")
    else:
        print("\n   Status: Both experiments pending conflict test results")
    
    # ç»¼åˆè¯„ä¼°
    print_section_header("ğŸ“Š ç»¼åˆè¯„ä¼°")
    
    print("\nâœ… å…³é”®å‘ç°:")
    print("-" * 80)
    
    # è®¡ç®—å¹³å‡å‡†ç¡®ç‡
    def calc_avg_accuracy(results: Dict) -> float:
        all_acc = []
        for test in ['test_g', 'test_a', 'test_b']:
            for adapter_data in results[test].values():
                if adapter_data.get('accuracy', 0) > 0:
                    all_acc.append(adapter_data['accuracy'])
        return sum(all_acc) / len(all_acc) if all_acc else 0
    
    exp001_avg = calc_avg_accuracy(exp001_results)
    exp002_avg = calc_avg_accuracy(exp002_results)
    
    print(f"\n1. å¹³å‡å‡†ç¡®ç‡:")
    print(f"   EXP001: {exp001_avg:.1%}")
    print(f"   EXP002: {exp002_avg:.1%}")
    print(f"   æå‡: {exp002_avg - exp001_avg:+.1%}")
    
    print(f"\n2. æ¨¡å‹å®¹é‡:")
    print(f"   EXP001 (r=16): æ›´è½»é‡ï¼Œè®­ç»ƒæ›´å¿«")
    print(f"   EXP002 (r=32): æ›´å¤§å®¹é‡ï¼Œè¡¨è¾¾èƒ½åŠ›æ›´å¼º")
    
    print(f"\n3. éšç§ä¿æŠ¤:")
    if exp001_privacy_a > 0 and exp002_privacy_a > 0:
        print(f"   Test-A Privacy Gap: EXP001={exp001_privacy_a:.1%}, EXP002={exp002_privacy_a:.1%}")
    if exp001_privacy_b > 0 and exp002_privacy_b > 0:
        print(f"   Test-B Privacy Gap: EXP001={exp001_privacy_b:.1%}, EXP002={exp002_privacy_b:.1%}")
    
    print(f"\n4. è®­ç»ƒæˆæœ¬:")
    print(f"   EXP001: 2 epochs/round Ã— 5 rounds = 10 epochs")
    print(f"   EXP002: 3 epochs/round Ã— 5 rounds = 15 epochs (+50%)")
    
    # ç»“è®º
    print_section_header("ğŸ¯ ç»“è®ºä¸å»ºè®®")
    
    print("\nå¦‚æœè¿½æ±‚:")
    print("  â€¢ æ›´é«˜å‡†ç¡®ç‡ â†’ é€‰æ‹© EXP002 (r=32, 3 epochs)")
    print("  â€¢ è®­ç»ƒæ•ˆç‡   â†’ é€‰æ‹© EXP001 (r=16, 2 epochs)")
    print("  â€¢ å¹³è¡¡æ–¹æ¡ˆ   â†’ EXP001 é…ç½®å·²è¶³å¤Ÿï¼Œæ€§ä»·æ¯”é«˜")
    
    print("\n" + "="*80)

if __name__ == "__main__":
    main()
