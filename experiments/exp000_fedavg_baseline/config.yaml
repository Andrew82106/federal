experiment:
  name: "exp000_fedavg_baseline"
  description: "Standard FedAvg baseline without dual-adapter architecture"
  seed: 42

model:
  base_model: "Qwen/Qwen2.5-7B-Instruct"
  quantization: "4bit"
  lora_config:
    r: 16
    lora_alpha: 32
    lora_dropout: 0.05
    target_modules:
      - "q_proj"
      - "k_proj"
      - "v_proj"
      - "o_proj"
      - "gate_proj"
      - "up_proj"
      - "down_proj"
    bias: "none"
    task_type: "CAUSAL_LM"

training:
  num_epochs: 2
  per_device_train_batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 2.0e-4
  weight_decay: 0.01
  warmup_ratio: 0.03
  lr_scheduler_type: "cosine"
  max_seq_length: 1024
  logging_steps: 10
  save_strategy: "epoch"
  fp16: true
  optim: "paged_adamw_8bit"

federated:
  num_rounds: 5
  num_clients: 2
  aggregation_method: "fedavg"
  client_names:
    - "client_mixed_1"
    - "client_mixed_2"

data:
  global_train: "data/rule_data/global_train.json"
  # 两个客户端使用相同的混合数据（模拟数据异构）
  client_mixed_1: "data/rule_data/client_mixed_baseline.json"
  client_mixed_2: "data/rule_data/client_mixed_baseline.json"
  test_global: "data/test/global_test.json"
  test_strict: "data/test/strict_test.json"
  test_service: "data/test/service_test.json"
  conflict_cases: "data/test/conflict_cases.json"

output:
  checkpoint_dir: "results/exp000_fedavg_baseline/checkpoints"
  log_dir: "results/exp000_fedavg_baseline/logs"
  metrics_dir: "results/exp000_fedavg_baseline/metrics"
